{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oYKhhy1Fp3e"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install lightning\n",
        "!pip install torchmetrics\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import lightning as pl\n",
        "import torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "from cProfile import label\n",
        "import os\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "#from pytorch_lightning.loggers import TensorBoardLogger\n",
        "#from lightning.pytorch import Trainer\n",
        "from lightning.pytorch import Trainer\n",
        "#from lightning.pytorch.loggers import TensorBoardLogger\n",
        "from torchmetrics.collections import MetricCollection\n",
        "from torchmetrics.classification import Accuracy, Precision, Recall  # Import the Accuracy, Precision, and Recall classes\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "\n",
        "\n",
        "torch.backends.cuda.max_split_size_mb = 10\n",
        "\n",
        "\n",
        "\n",
        "class LambdaLayer(pl.LightningModule):\n",
        "    def __init__(self, lambd):  #run when object of LambdaLayer is initiaed\n",
        "        super(LambdaLayer, self).__init__() #initialize object\n",
        "        self.lambd = lambd\n",
        "        #applies lamdbda function\n",
        "\n",
        "    def forward(self, x):  # x = input tensor\n",
        "        return self.lambd(x)\n",
        "\n",
        "\n",
        "\n",
        "class BasicConvBlock(pl.LightningModule):\n",
        "  def __init__(self, in_channels, out_channels, stride=1, option='A'):  # option A - default shortcut connection\n",
        "      super(BasicConvBlock, self).__init__()\n",
        "      #initialization of Block object\n",
        "\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "      self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "      self.activation1 = nn.ReLU()\n",
        "      self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "      self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "      #defince components of convolution block\n",
        "\n",
        "      self.shortcut = nn.Identity()\n",
        "      #define shortcut connection for ResNet architecture\n",
        "\n",
        "\n",
        "\n",
        "      if stride != 1 or in_channels != out_channels:  #conditions meant --> shortcut needs to be adjusted\n",
        "          pad_channels = out_channels // 4\n",
        "          self.shortcut = LambdaLayer(lambda x: F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, pad_channels, pad_channels, 0, 0)))\n",
        "          #alters padding of input tensor\n",
        "          #dimensions of the tensor align during forwards passing\n",
        "\n",
        "  def forward(self, x):  #actual passing of data and application of block parameters\n",
        "      out = self.conv1(x)\n",
        "      out = self.batch_norm1(out)\n",
        "      out = self.activation1(out)\n",
        "      out = self.conv2(out)\n",
        "      out = self.batch_norm2(out)\n",
        "\n",
        "      shortcut_out = self.shortcut(x)\n",
        "      out += shortcut_out\n",
        "      out = F.relu(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class Network(pl.LightningModule):  #pl.LightningModule\n",
        "\n",
        "    def __init__(self, block_type, block_num):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.in_channels = 16  # no of input channels\n",
        "\n",
        "        self.conv0 = self._conv_block(3, 16, kernel_size=3, stride=1, padding=1, bias=False)#layer 0:performs conv operation, batch, RELU\n",
        "\n",
        "        self.blocks = nn.ModuleList()  #list for block layers\n",
        "        self.blocks.append(self._layer_block(block_type, 16, block_num[0], starting_stride=1))\n",
        "        self.blocks.append(self._layer_block(block_type, 32, block_num[1], starting_stride=2))\n",
        "        self.blocks.append(self._layer_block(block_type, 64, block_num[2], starting_stride=2))\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.linear = nn.Linear(64, 10) #64-dimensional input --> 10-dimensional output\n",
        "        self.num_classes = 101\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "        #self.accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "        '''self.metric_collection = torchmetrics.metric_collection = MetricCollection({\n",
        "            'acc': torchmetrics.Accuracy(),\n",
        "            #'prec': Precision(num_classes=10, average='macro'),\n",
        "            #'rec': Recall(num_classes=10, average='macro')\n",
        "        })'''\n",
        "\n",
        "\n",
        "    def _conv_block(self, in_channels, out_channels, **kwargs): #helper method to create convolutional block\n",
        "        return nn.Sequential( #defines the sequential operations of the block\n",
        "            nn.Conv2d(in_channels, out_channels, **kwargs), #2d convolution\n",
        "            nn.BatchNorm2d(out_channels), #batch normalization\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "    def _layer_block(self, block_type, out_channels, block_num, starting_stride):  #creates block layer\n",
        "            strides_list = [starting_stride] + [1] * (block_num - 1)\n",
        "            layers = []\n",
        "\n",
        "            for stride in strides_list:\n",
        "                layers.append(block_type(self.in_channels, out_channels, stride))\n",
        "                self.in_channels = out_channels\n",
        "\n",
        "            return nn.Sequential(*layers) #creates all the block instances\n",
        "\n",
        "    def forward(self, x): #forward pass of data\n",
        "        x = self.conv0(x)\n",
        "        for block in self.blocks: #list of layers of the network\n",
        "            x = block(x)\n",
        "        x = self.avgpool(x) #adaptive average pooling --> fixed-size representation\n",
        "        x = torch.flatten(x, 1) #collapes tensor dimenion (except for batch)\n",
        "        x = self.linear(x) #linear transformation to tensor that creates comprehensenable result\n",
        "        return x\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        prediction = self(inputs)\n",
        "        loss = F.cross_entropy(prediction, labels)\n",
        "        #self.log('train_loss', loss, on_epoch=True)  # Logging the training loss\n",
        "        accuracy = torchmetrics.Accuracy(task = 'multiclass', num_classes=self.num_classes).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "        #accuracy = Accuracy(task = 'multiclass', num_classes = self.num_classes)\n",
        "        #acc = self.accuracy(prediction, labels)\n",
        "        #self.log_weights_and_biases()\n",
        "        #self.log('accuracy', acc, on_epoch=True)\n",
        "        #self.metric_collection.update(prediction, labels)\n",
        "        #acc = accuracy(prediction, labels)\n",
        "        acc = accuracy(prediction.argmax(dim=1), labels)\n",
        "\n",
        "        #self.log('accuracy', acc, on_epoch=True)\n",
        "\n",
        "\n",
        "        #self.log_dict(self.metric_collection, on_step=False, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      preds = self.forward(x)\n",
        "      loss = self.criterion(preds, y)\n",
        "      accuracy2 = Accuracy(task=\"multiclass\", num_classes=100)\n",
        "      accu = accuracy2(preds, y)\n",
        "      self.log('accuracy_validation', accu, on_epoch=True)\n",
        "      return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      return optim.Adam(self.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "def ResNet18_test():\n",
        "    return Network(block_type = BasicConvBlock , block_num = [2,2,2,2])\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "resnet = ResNet18_test()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "resnet.to(device)\n",
        "summary(resnet, (3,32,32))\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "os.chdir('/content/drive/My Drive/')#change google drive directory\n",
        "\n",
        "\n",
        "crit = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "\n",
        "def train_resnet():\n",
        "    epochs = 15\n",
        "    train_samples_num = 45000\n",
        "    val_samples_num = 5000\n",
        "    train_costs, val_costs = [], [] #to store training and validation losses\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        resnet.train()\n",
        "        train_running_loss = 0\n",
        "        correct_train = 0\n",
        "\n",
        "        for inputs, labels in trainLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad() #optimizer set to 0\n",
        "\n",
        "            #start forwading data\n",
        "            prediction = resnet(inputs)\n",
        "\n",
        "            loss = crit(prediction, labels)\n",
        "\n",
        "            #backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted_outputs = torch.max(prediction.data, 1)\n",
        "            correct_train += (predicted_outputs == labels).sum().item()\n",
        "            #calculates number of correctly predicted trainign samples\n",
        "\n",
        "        train_epoch_loss = train_running_loss / train_samples_num #avg training loss\n",
        "        train_costs.append(train_epoch_loss)\n",
        "        train_acc = correct_train / train_samples_num #accuracy\n",
        "\n",
        "        resnet.eval() #evaluation mode - dropout and batch normalization are disabled\n",
        "        val_running_loss = 0\n",
        "        correct_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testLoader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "                prediction = resnet(inputs)\n",
        "\n",
        "                loss = crit(prediction, labels)\n",
        "\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                _, predicted_outputs = torch.max(prediction.data, 1)\n",
        "                correct_val += (predicted_outputs == labels).sum().item()\n",
        "\n",
        "        val_epoch_loss = val_running_loss / val_samples_num\n",
        "        val_costs.append(val_epoch_loss)\n",
        "        val_acc = correct_val / val_samples_num\n",
        "\n",
        "        info = \"[Epoch {}/{}]: train-loss = {:0.6f} | train-acc = {:0.3f} | val-loss = {:0.6f} | val-acc = {:0.3f}\"\n",
        "        print(info.format(epoch+1, epochs, train_epoch_loss, train_acc, val_epoch_loss, val_acc)) #training process\n",
        "\n",
        "        torch.save(resnet.state_dict(), '/content/checkpoint_gpu_{}'.format(epoch + 1)) #saves dictionary of trained model\n",
        "\n",
        "    torch.save(resnet.state_dict(), '/content/resnet-18_weights_gpu') #final trained model dictionary is saved\n",
        "\n",
        "    '''wandb.log({\n",
        "                \"Epoch\": epoch,\n",
        "                \"Train Loss\": val_epoch_loss,\n",
        "                \"Train Acc\": val_acc,\n",
        "                \"Valid Loss\": loss,\n",
        "                #\"Valid Acc\": acc_valid\n",
        "                })'''\n",
        "    return train_costs, val_costs\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resnet = Network(block_type=BasicConvBlock, block_num=[2, 2, 2, 2])\n",
        "    trainLoader, testLoader, test_data = data()\n",
        "    valid_loader = DataLoader(test_data)\n",
        "\n",
        "    # Create a PyTorch Lightning Trainer\n",
        "    #trainer = pl.Trainer(max_epochs=15, gpus=1 if torch.cuda.is_available() else 0)\n",
        "\n",
        "\n",
        "    csv_logger = CSVLogger('caltech_logs2/logs/', name='my_experiment')\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        trainer = pl.Trainer(max_epochs=15, logger=csv_logger) #tb_logger\n",
        "    else:\n",
        "        trainer = pl.Trainer(max_epochs=15, logger=csv_logger)\n",
        "\n",
        "    validation_fraction = 0.1  # Adjust this as needed\n",
        "\n",
        "    # Train the model using the PyTorch Lightning Trainer\n",
        "    #trainer.fit(resnet, trainLoader, valid_loader)\n",
        "\n",
        "\n",
        "    trainer.fit(resnet, trainLoader)\n",
        "\n",
        "\n",
        "    # Save the final trained model weights\n",
        "    torch.save(resnet.state_dict(), '/content/resnet-18_weights_gpu')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}